### 📊 **1. Linear Regression Methods**

#### 🔹 **a. Simple Linear Regression**

* **Definition:** One dependent variable, one independent variable.
* **Use:** Straight-line relationship.

#### 🔹 **b. Multiple Linear Regression**

* **Definition:** One dependent variable, **two or more independent variables**.
* **Use:** Predict based on multiple factors.

---

### 📈 **2. Polynomial Regression**

* **Definition:** Models **non-linear relationships** by adding polynomial terms (X², X³, etc.).
* **Use:** When data shows a curved trend.

---

### 🧮 **3. Ridge Regression (L2 Regularization)**

* **Definition:** Adds a penalty term proportional to the square of the coefficients to avoid overfitting.
* **Use:** When multicollinearity exists.

---

### 📝 **4. Lasso Regression (L1 Regularization)**

* **Definition:** Adds a penalty proportional to the absolute value of coefficients.
* **Use:** Performs **feature selection** by shrinking some coefficients to zero.

---

### 🔧 **5. Elastic Net Regression**

* **Definition:** Combination of Ridge and Lasso.
* **Use:** When there are multiple correlated features and feature selection is desired.

---

### ⚖️ **6. Logistic Regression**

* **Definition:** Used for **classification**, predicts probability (output between 0 and 1).
* **Use:** Binary outcomes (Yes/No, 0/1).

---

### 📊 **7. Stepwise Regression**

* **Definition:** Automated method to select significant variables by adding or removing predictors based on criteria (AIC/BIC/p-values).
* **Types:**

  * Forward Selection
  * Backward Elimination
  * Bidirectional Elimination

---

### 🔎 **8. Quantile Regression**

* **Definition:** Models conditional quantiles (e.g. median regression instead of mean).
* **Use:** When interested in predicting medians or other quantiles rather than means.

---

### 🧠 **9. Non-linear Regression**

* **Definition:** Fits models where parameters enter non-linearly.
* **Use:** Complex real-world relationships (e.g. exponential, logarithmic, sigmoid growth).

---

### 🌳 **10. Robust Regression**

* **Definition:** Reduces influence of outliers.
* **Methods:** M-estimators, RANSAC.

---

### 🌐 **11. Bayesian Regression**

* **Definition:** Uses Bayesian inference for estimating regression coefficients.
* **Use:** When incorporating prior beliefs or handling uncertainty.

---

### 🤖 **12. Advanced Machine Learning Regression Techniques**

#### 🔹 **a. Decision Tree Regression**

* Models data by splitting based on feature values.

#### 🔹 **b. Random Forest Regression**

* Uses an ensemble of decision trees to improve predictions.

#### 🔹 **c. Support Vector Regression (SVR)**

* Uses support vector machines for regression tasks.

#### 🔹 **d. K-Nearest Neighbors Regression**

* Predicts based on the average of K nearest data points.

#### 🔹 **e. Gradient Boosting Regression (XGBoost, LightGBM)**

* Builds strong models by combining weak learners sequentially.

#### 🔹 **f. Neural Network Regression**

* Uses deep learning models for complex non-linear regression.

---

### ✅ **Summary Table**

| **Method**      | **Key Use**                              |
| --------------- | ---------------------------------------- |
| Simple Linear   | One predictor, straight line             |
| Multiple Linear | Multiple predictors                      |
| Polynomial      | Non-linear trends                        |
| Ridge           | Multicollinearity control                |
| Lasso           | Feature selection                        |
| Elastic Net     | Combines Ridge + Lasso                   |
| Logistic        | Classification                           |
| Stepwise        | Automated variable selection             |
| Quantile        | Predicting quantiles                     |
| Non-linear      | Complex non-linear models                |
| Robust          | Outlier resistance                       |
| Bayesian        | Bayesian inference                       |
| ML Techniques   | Complex, large-scale predictive modeling |

---
