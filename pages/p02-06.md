# üìö **üåü Logistic Regression (Classification)**

### **Introduction to Logistic Regression (Classification)**

Logistic Regression is a fundamental classification algorithm used to model the probability of a **binary outcome** based on one or more predictor variables. Despite its name, logistic regression is primarily used for **classification tasks**, not regression.

**Key aspects of Logistic Regression include:**

* **Equation Form:**
  Logistic Regression predicts the probability of the dependent variable belonging to a particular class using the logistic (sigmoid) function:

  $$
  P(y=1|x) = \frac{1}{1 + e^{-(Œ≤_0 + Œ≤_1x_1 + Œ≤_2x_2 + ... + Œ≤_kx_k)}}
  $$

  where:

  * *P(y=1|x)* is the probability that the output is class 1 given input *x*,
  * *Œ≤‚ÇÄ* is the intercept,
  * *Œ≤‚ÇÅ, Œ≤‚ÇÇ, ..., Œ≤\_k* are coefficients for each predictor.

* **Interpretation:**

  * The model outputs probabilities between 0 and 1. A threshold (typically 0.5) is used to classify observations into one of the two classes.
  * The coefficients (*Œ≤\_j*) indicate the **log-odds change** in the outcome for a one-unit increase in the predictor, holding other variables constant.

* **Key advantages:**

  * **Simplicity and efficiency:** Easy to implement and interpret.
  * **Probabilistic output:** Provides probability estimates useful for decision-making.
  * **Baseline for classification:** Often used as a benchmark before applying more complex models.

* **Assumptions:**
  Logistic Regression makes the following assumptions:

  * The dependent variable is binary (or can be extended to multinomial and ordinal cases).
  * Independence of observations.
  * Little or no multicollinearity among predictors.
  * Linearity of independent variables with the **logit of the outcome** (not with the outcome directly).

* **Extensions:**

  * **Multinomial Logistic Regression:** For multi-class classification problems.
  * **Ordinal Logistic Regression:** For ordinal outcomes with natural ordering.

* **Applications:**
  Logistic Regression is widely used in:

  * **Medical research:** Predicting disease presence or absence based on symptoms and test results.
  * **Finance:** Determining likelihood of loan default.
  * **Marketing:** Predicting customer churn or conversion likelihood.
  * **Social sciences:** Analyzing binary survey responses.

Due to its simplicity, interpretability, and effectiveness in binary classification tasks, logistic regression remains one of the most widely used algorithms in statistics, data analysis, and machine learning.

---

### üìù **üîπ Step 0: Problem Setup**

**Example Problem:**
Predict whether a **house price exceeds \$250,000** based on **area and bedrooms**. Here, the output is **binary (Yes/No or 0/1)**.

---

### üîπ **Step 1: Import Libraries**

```python
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
```

---

### üîπ **Step 2: Create Sample Data**

```python
# Sample dataset
data = {
    'Area': [500, 750, 1000, 1250, 1500],
    'Bedrooms': [1, 2, 2, 3, 3],
    'Price': [150000, 200000, 250000, 300000, 350000]
}
df = pd.DataFrame(data)

# Create binary target: 1 if price > 250000, else 0
df['Expensive'] = np.where(df['Price'] > 250000, 1, 0)

print(df)
```

‚úÖ **Why Logistic Regression?**

* For predicting **probabilities and classification** (binary or multiclass).

---

### üîπ **Step 3: Prepare Data**

```python
X = df[['Area', 'Bedrooms']]
y = df['Expensive']
```

---

### üîπ **Step 4: Fit Logistic Regression Model**

```python
model = LogisticRegression()
model.fit(X, y)
```

---

### üîπ **Step 5: Check Model Parameters**

```python
print(f"Intercept: {model.intercept_}")
print(f"Coefficients: {model.coef_}")
```

‚úÖ **Interpretation:**

* Coefficients indicate how each predictor affects the **log-odds of being expensive**.

---

### üîπ **Step 6: Make Predictions**

```python
# Predict classes (0 or 1)
predicted_class = model.predict(X)
print(predicted_class)

# Predict probabilities
predicted_prob = model.predict_proba(X)
print(predicted_prob)
```

---

### üîπ **Step 7: Evaluate Model**

```python
# Accuracy
accuracy = accuracy_score(y, predicted_class)
print(f"Accuracy: {accuracy}")

# Confusion Matrix
cm = confusion_matrix(y, predicted_class)
print(f"Confusion Matrix:\n{cm}")

# Classification Report
report = classification_report(y, predicted_class)
print(f"Classification Report:\n{report}")
```

‚úÖ **Interpretation:**

* **Accuracy:** Overall correctness.
* **Confusion Matrix:** True positives, true negatives, false positives, false negatives.
* **Classification Report:** Precision, recall, F1-score.

---

### üîπ **Step 8: Applicability of Logistic Regression**

| **When to use?**                                 | **When not to use?**                            |
| ------------------------------------------------ | ----------------------------------------------- |
| Output is **categorical (binary or multiclass)** | Output is **continuous**                        |
| Predicting **probability of an event**           | Non-linear relationships without transformation |
| Classification tasks (pass/fail, yes/no)         |                                                 |

---

### üìù **End of Part 7**

---


