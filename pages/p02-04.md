# 📚 **🌟 Lasso Regression (L1 Regularization)**

---

### 📝 **🔹 Step 0: Problem Setup**

**Example Problem:**
Predict **house price (Y)** based on **multiple features**, while **selecting only the important predictors** (some coefficients may become zero).

---

### 🔹 **Step 1: Import Libraries**

```python
import pandas as pd
import numpy as np
from sklearn.linear_model import Lasso
from sklearn.metrics import mean_squared_error, r2_score
```

---

### 🔹 **Step 2: Create Sample Data**

```python
# Sample dataset with multiple features
data = {
    'Area': [500, 750, 1000, 1250, 1500],
    'Bedrooms': [1, 2, 2, 3, 3],
    'Age': [5, 7, 10, 12, 15],
    'Distance': [2, 3, 5, 7, 8],
    'Price': [150000, 200000, 250000, 300000, 350000]
}
df = pd.DataFrame(data)
print(df)
```

✅ **Why Lasso Regression?**

* **Performs feature selection** by shrinking some coefficients to zero, keeping only significant predictors.

---

### 🔹 **Step 3: Prepare Data**

```python
X = df[['Area', 'Bedrooms', 'Age', 'Distance']]
y = df['Price']
```

---

### 🔹 **Step 4: Fit Lasso Regression Model**

```python
model = Lasso(alpha=1.0)  # alpha controls regularization strength
model.fit(X, y)
```

✅ **Note:**

* **Higher alpha:** More coefficients set to zero (stronger selection).
* **Lower alpha:** Closer to linear regression.

---

### 🔹 **Step 5: Check Model Parameters**

```python
print(f"Intercept: {model.intercept_}")
print(f"Coefficients: {model.coef_}")
```

✅ **Interpretation:**

* Coefficients with **zero value** are **excluded from the model**.

---

### 🔹 **Step 6: Make Predictions**

```python
new_data = pd.DataFrame({
    'Area': [1100, 1600],
    'Bedrooms': [2, 3],
    'Age': [9, 14],
    'Distance': [4, 7]
})
predicted_price = model.predict(new_data)
print(predicted_price)
```

---

### 🔹 **Step 7: Evaluate Model**

```python
y_pred = model.predict(X)
mse = mean_squared_error(y, y_pred)
r2 = r2_score(y, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```

---

### 🔹 **Step 8: Applicability of Lasso Regression**

| **When to use?**                             | **When not to use?**                            |
| -------------------------------------------- | ----------------------------------------------- |
| **Feature selection** is needed              | When all predictors are needed                  |
| Large number of predictors, some unimportant | Predictors are highly correlated (Ridge better) |
| Sparse model desired                         |                                                 |

---

### 📝 **End of Part 5**

---
