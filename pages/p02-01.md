# ğŸ“š **ğŸŒŸ Simple Linear Regression**

---

### ğŸ“ **ğŸ”¹ Step 0: Problem Setup**

**Example Problem:**
Predict **house price (Y)** based on **area in sq. ft. (X)**.

---

### ğŸ”¹ **Step 1: Import Libraries**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
```

---

### ğŸ”¹ **Step 2: Create Sample Data**

```python
# Creating a simple dataset
data = {
    'Area': [500, 750, 1000, 1250, 1500],
    'Price': [150000, 200000, 250000, 300000, 350000]
}
df = pd.DataFrame(data)
print(df)
```

âœ… **Why this method?**

* **Applicability:** When **one independent variable** is used to predict a **continuous dependent variable** with **linear relationship**.

---

### ğŸ”¹ **Step 3: Visualize Data**

```python
plt.scatter(df['Area'], df['Price'], color='blue')
plt.xlabel('Area (sq ft)')
plt.ylabel('Price ($)')
plt.title('Area vs Price')
plt.show()
```

---

### ğŸ”¹ **Step 4: Prepare Data for Model**

```python
X = df[['Area']]  # Independent variable as 2D array
y = df['Price']   # Dependent variable as 1D array
```

---

### ğŸ”¹ **Step 5: Fit Simple Linear Regression Model**

```python
model = LinearRegression()
model.fit(X, y)
```

---

### ğŸ”¹ **Step 6: Check Model Parameters**

```python
print(f"Intercept (a): {model.intercept_}")
print(f"Slope (b): {model.coef_[0]}")
```

---

### ğŸ”¹ **Step 7: Make Predictions**

```python
# Predict price for new area values
new_area = pd.DataFrame({'Area': [1100, 1600]})
predicted_price = model.predict(new_area)
print(predicted_price)
```

---

### ğŸ”¹ **Step 8: Plot Regression Line**

```python
plt.scatter(df['Area'], df['Price'], color='blue')
plt.plot(df['Area'], model.predict(X), color='red')  # Regression line
plt.xlabel('Area (sq ft)')
plt.ylabel('Price ($)')
plt.title('Area vs Price with Regression Line')
plt.show()
```

---

### ğŸ”¹ **Step 9: Evaluate Model**

```python
from sklearn.metrics import mean_squared_error, r2_score

y_pred = model.predict(X)
mse = mean_squared_error(y, y_pred)
r2 = r2_score(y, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```

âœ… **Interpretation:**

* **RÂ² near 1:** Strong fit
* **MSE small:** Predictions close to actual values

---

### ğŸ”¹ **Step 10: Applicability of Simple Linear Regression**

| **When to use?**                                             | **When not to use?**              |
| ------------------------------------------------------------ | --------------------------------- |
| Predicting **continuous outcomes** based on **one variable** | Relationship is **not linear**    |
| Relationship is approximately **straight line**              | There are **multiple predictors** |
| Checking **trend or association strength**                   | High variance in residuals        |

---

### ğŸ“ **End of Part 1**

---

# ğŸ“š **ğŸŒŸ Multiple Linear Regression**

---

### ğŸ“ **ğŸ”¹ Step 0: Problem Setup**

**Example Problem:**
Predict **house price (Y)** based on **area (X1)** and **number of bedrooms (X2)**.

---

### ğŸ”¹ **Step 1: Import Libraries**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
```

---

### ğŸ”¹ **Step 2: Create Sample Data**

```python
# Creating a sample dataset
data = {
    'Area': [500, 750, 1000, 1250, 1500],
    'Bedrooms': [1, 2, 2, 3, 3],
    'Price': [150000, 200000, 250000, 300000, 350000]
}
df = pd.DataFrame(data)
print(df)
```

âœ… **Why this method?**

* **Applicability:** When **more than one independent variable** is used to predict a **continuous dependent variable**.

---

### ğŸ”¹ **Step 3: Prepare Data for Model**

```python
X = df[['Area', 'Bedrooms']]  # Multiple independent variables
y = df['Price']               # Dependent variable
```

---

### ğŸ”¹ **Step 4: Fit Multiple Linear Regression Model**

```python
model = LinearRegression()
model.fit(X, y)
```

---

### ğŸ”¹ **Step 5: Check Model Parameters**

```python
print(f"Intercept: {model.intercept_}")
print(f"Coefficients: {model.coef_}")
```

âœ… **Interpretation:**

* **Intercept:** Base price when all predictors are 0
* **Coefficients:** Effect of each predictor on price

---

### ğŸ”¹ **Step 6: Make Predictions**

```python
# Predict price for new area and bedrooms
new_data = pd.DataFrame({
    'Area': [1100, 1600],
    'Bedrooms': [2, 3]
})
predicted_price = model.predict(new_data)
print(predicted_price)
```

---

### ğŸ”¹ **Step 7: Evaluate Model**

```python
from sklearn.metrics import mean_squared_error, r2_score

y_pred = model.predict(X)
mse = mean_squared_error(y, y_pred)
r2 = r2_score(y, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```

âœ… **Interpretation:**

* **RÂ² near 1:** Strong fit
* **MSE small:** Predictions close to actual values

---

### ğŸ”¹ **Step 8: Applicability of Multiple Linear Regression**

| **When to use?**                                                    | **When not to use?**                                     |
| ------------------------------------------------------------------- | -------------------------------------------------------- |
| Predicting **continuous outcomes** based on **multiple predictors** | Predictors are **highly correlated** (multicollinearity) |
| Relationships are approximately **linear**                          | Relationship is **not linear**                           |
| Checking **combined effects** of variables                          | Data has **non-linear trends**                           |

---

### ğŸ“ **End of Part 2**

---
