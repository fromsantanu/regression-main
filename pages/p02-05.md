# 📚 **🌟 Elastic Net Regression (Combination of L1 & L2 Regularization)**

---

### 📝 **🔹 Step 0: Problem Setup**

**Example Problem:**
Predict **house price (Y)** based on **multiple features**, combining the benefits of **Ridge (L2)** and **Lasso (L1)** regularizations.

---

### 🔹 **Step 1: Import Libraries**

```python
import pandas as pd
import numpy as np
from sklearn.linear_model import ElasticNet
from sklearn.metrics import mean_squared_error, r2_score
```

---

### 🔹 **Step 2: Create Sample Data**

```python
# Sample dataset with multiple features
data = {
    'Area': [500, 750, 1000, 1250, 1500],
    'Bedrooms': [1, 2, 2, 3, 3],
    'Age': [5, 7, 10, 12, 15],
    'Distance': [2, 3, 5, 7, 8],
    'Price': [150000, 200000, 250000, 300000, 350000]
}
df = pd.DataFrame(data)
print(df)
```

✅ **Why Elastic Net Regression?**

* When:

  * There are **multiple correlated predictors**.
  * You want **feature selection (Lasso)** plus **stability (Ridge)**.

---

### 🔹 **Step 3: Prepare Data**

```python
X = df[['Area', 'Bedrooms', 'Age', 'Distance']]
y = df['Price']
```

---

### 🔹 **Step 4: Fit Elastic Net Regression Model**

```python
model = ElasticNet(alpha=1.0, l1_ratio=0.5)  # l1_ratio=0.5 means equal balance of L1 and L2
model.fit(X, y)
```

✅ **Notes:**

* **alpha:** Overall regularization strength.
* **l1\_ratio:**

  * **0:** Equivalent to Ridge.
  * **1:** Equivalent to Lasso.
  * **0.5:** Equal combination.

---

### 🔹 **Step 5: Check Model Parameters**

```python
print(f"Intercept: {model.intercept_}")
print(f"Coefficients: {model.coef_}")
```

✅ **Interpretation:**

* Some coefficients may be **shrunk to zero** (feature selection) while others are **regularized** (controlled).

---

### 🔹 **Step 6: Make Predictions**

```python
new_data = pd.DataFrame({
    'Area': [1100, 1600],
    'Bedrooms': [2, 3],
    'Age': [9, 14],
    'Distance': [4, 7]
})
predicted_price = model.predict(new_data)
print(predicted_price)
```

---

### 🔹 **Step 7: Evaluate Model**

```python
y_pred = model.predict(X)
mse = mean_squared_error(y, y_pred)
r2 = r2_score(y, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```

---

### 🔹 **Step 8: Applicability of Elastic Net Regression**

| **When to use?**                                                    | **When not to use?**                    |
| ------------------------------------------------------------------- | --------------------------------------- |
| **Many correlated variables** with desire for **feature selection** | Pure Ridge or Lasso is sufficient       |
| Model needs **stability + sparsity**                                | Small dataset with no multicollinearity |
| High-dimensional data (more predictors than samples)                |                                         |

---

### 📝 **End of Part 6**

---
