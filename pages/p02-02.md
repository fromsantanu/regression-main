# 📚 **🌟 Polynomial Regression**

---

### 📝 **🔹 Step 0: Problem Setup**

**Example Problem:**
Predict **house price (Y)** based on **area (X)** where the relationship is **non-linear (curved)**.

---

### 🔹 **Step 1: Import Libraries**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
```

---

### 🔹 **Step 2: Create Sample Data**

```python
# Creating a sample dataset with non-linear relationship
data = {
    'Area': [500, 750, 1000, 1250, 1500],
    'Price': [150000, 210000, 290000, 400000, 550000]
}
df = pd.DataFrame(data)
print(df)
```

✅ **Why this method?**

* **Applicability:** When **data shows curvature**, not a straight line.

---

### 🔹 **Step 3: Visualize Data**

```python
plt.scatter(df['Area'], df['Price'], color='blue')
plt.xlabel('Area (sq ft)')
plt.ylabel('Price ($)')
plt.title('Area vs Price (Possible Curve)')
plt.show()
```

---

### 🔹 **Step 4: Transform Data to Polynomial Features**

```python
X = df[['Area']]  # Independent variable as 2D array
y = df['Price']

# Transform to polynomial features (degree=2 for quadratic)
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X)
```

✅ **What happened here?**

* Adds **additional columns** for Area² to capture the curve.

---

### 🔹 **Step 5: Fit Polynomial Regression Model**

```python
model = LinearRegression()
model.fit(X_poly, y)
```

---

### 🔹 **Step 6: Check Model Parameters**

```python
print(f"Intercept: {model.intercept_}")
print(f"Coefficients: {model.coef_}")
```

✅ **Interpretation:**

* **Coefficients:** For Area⁰ (intercept), Area¹ (linear), Area² (quadratic).

---

### 🔹 **Step 7: Make Predictions**

```python
# Predict prices for given areas
new_area = pd.DataFrame({'Area': [1100, 1600]})
new_area_poly = poly.transform(new_area)
predicted_price = model.predict(new_area_poly)
print(predicted_price)
```

---

### 🔹 **Step 8: Plot Polynomial Regression Curve**

```python
# Scatter plot
plt.scatter(df['Area'], df['Price'], color='blue')

# Regression curve
area_range = np.linspace(df['Area'].min(), df['Area'].max(), 100).reshape(-1,1)
area_range_poly = poly.transform(area_range)
price_pred = model.predict(area_range_poly)

plt.plot(area_range, price_pred, color='red')
plt.xlabel('Area (sq ft)')
plt.ylabel('Price ($)')
plt.title('Polynomial Regression: Area vs Price')
plt.show()
```

---

### 🔹 **Step 9: Evaluate Model**

```python
from sklearn.metrics import mean_squared_error, r2_score

y_pred = model.predict(X_poly)
mse = mean_squared_error(y, y_pred)
r2 = r2_score(y, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```

✅ **Interpretation:**

* **R² near 1:** Good fit to non-linear data
* **MSE small:** Predictions close to actual

---

### 🔹 **Step 10: Applicability of Polynomial Regression**

| **When to use?**                           | **When not to use?**                    |
| ------------------------------------------ | --------------------------------------- |
| Relationship is **curved/non-linear**      | Overfitting risk if **degree too high** |
| Data shows **quadratic or cubic patterns** | When relationship is truly linear       |
| Adding polynomial terms improves fit       | For extrapolation far beyond data       |

---

### 📝 **End of Part 3**

---

